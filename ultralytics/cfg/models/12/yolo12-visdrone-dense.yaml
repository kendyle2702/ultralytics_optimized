# Ultralytics ðŸš€ AGPL-3.0 License - https://ultralytics.com/license

# YOLO12-Visdrone-Dense: Dense multi-scale architecture for extreme small object detection
# Maximum feature reuse with DenseNet-inspired connections
# Key innovations:
#   - Dense cross-scale feature connections
#   - Triple-level feature fusion (P2, P3, P4 interconnected)
#   - Attention gates for adaptive feature selection
#   - Optimized for detecting very small objects (< 32x32 pixels)
#   - Best for scenarios with birds, pedestrians at distance, small vehicles

# Parameters
nc: 10  # Visdrone classes
scales: # model compound scaling constants
  # [depth, width, max_channels]
  n: [0.50, 0.35, 1024] # Dense connections need more channels
  s: [0.50, 0.60, 1024] # Recommended starting point
  m: [0.60, 1.00, 512]  # Best balance
  l: [0.80, 1.00, 512]  # Maximum accuracy
  x: [1.00, 1.50, 512]  # Research/competition use

# YOLO12-Visdrone-Dense backbone
backbone:
  # [from, repeats, module, args]
  - [-1, 1, Conv, [64, 3, 2]]   # 0-P1/2
  - [-1, 1, Conv, [128, 3, 2]]  # 1-P2/4
  - [-1, 3, C3k2, [128, False, 0.25]]  # 2 P2 features
  - [-1, 1, Conv, [256, 3, 2]]  # 3-P3/8
  - [-1, 3, C3k2, [256, False, 0.25]]  # 4 P3 features
  - [-1, 1, Conv, [512, 3, 2]]  # 5-P4/16
  - [-1, 4, A2C2f, [512, True, 4]]  # 6 P4 features
  - [-1, 1, Conv, [1024, 3, 2]] # 7-P5/32
  - [-1, 4, A2C2f, [1024, True, 1]] # 8 P5 features
  - [-1, 1, SPPF, [1024, 5]]    # 9 Global context

# YOLO12-Visdrone-Dense head - Dense FPN with maximum connectivity
head:
  # === Top-down path - Level 1 ===
  - [-1, 1, nn.Upsample, [None, 2, "nearest"]]  # 10 up to P4
  - [[-1, 6], 1, Concat, [1]]   # 11 P4_td1 = P5 + P4_backbone
  - [-1, 2, A2C2f, [512, False, -1]]  # 12 P4_td1_processed

  - [-1, 1, nn.Upsample, [None, 2, "nearest"]]  # 13 up to P3
  - [[-1, 4], 1, Concat, [1]]   # 14 P3_td1 = P4_td1 + P3_backbone
  - [-1, 2, A2C2f, [256, False, -1]]  # 15 P3_td1_processed
  
  - [-1, 1, nn.Upsample, [None, 2, "nearest"]]  # 16 up to P2
  - [[-1, 2], 1, Concat, [1]]   # 17 P2_td1 = P3_td1 + P2_backbone
  - [-1, 2, C3k2, [128, False]]  # 18 P2_td1_processed

  # === Bottom-up path with dense connections ===
  # P2 enhanced (detection level 1)
  - [-1, 1, ChannelAttention, [128]]  # 19 P2 channel attention
  - [-1, 1, SpatialAttention, []]     # 20 P2 spatial attention
  
  # P2 -> P3 dense fusion
  - [20, 1, Conv, [128, 3, 2]]   # 21 P2 down
  - [[-1, 15], 1, Concat, [1]]   # 22 Dense: P2_down + P3_td1
  - [-1, 2, C2fAttn, [256]]      # 23 P3 enhanced (detection level 2)
  
  # P3 -> P4 dense fusion (with skip from P2)
  - [23, 1, Conv, [256, 3, 2]]   # 24 P3 down
  - [[-1, 12], 1, Concat, [1]]   # 25 Dense: P3_down + P4_td1
  - [-1, 2, A2C2f, [512, False, -1]]  # 26 P4 enhanced
  
  # Cross-scale P2->P4 direct connection (innovative!)
  - [20, 1, Conv, [128, 3, 4]]   # 27 P2 down with stride 4 (direct to P4 scale)
  - [[-1, 26], 1, Concat, [1]]   # 28 Add P2 info directly to P4
  - [-1, 1, Conv, [512, 1, 1]]   # 29 P4 final (detection level 3)
  
  # P4 -> P5 fusion
  - [26, 1, Conv, [512, 3, 2]]   # 30 P4 down
  - [[-1, 9], 1, Concat, [1]]    # 31 P4_down + P5_backbone
  - [-1, 2, C3k2, [1024, True]]  # 32 P5 final (detection level 4)

  # === Attention enhancement for small object levels ===
  - [20, 1, CBAM, [128]]         # 33 P2 output with CBAM
  - [23, 1, CBAM, [256]]         # 34 P3 output with CBAM

  # Dense multi-scale detection with 4 heads
  - [[33, 34, 29, 32], 1, Detect, [nc]]  # 35 Detect(P2, P3, P4, P5)

