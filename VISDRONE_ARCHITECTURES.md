# YOLOv12-Visdrone: Kiáº¿n trÃºc tá»‘i Æ°u cho phÃ¡t hiá»‡n Ä‘á»‘i tÆ°á»£ng nhá»

## Tá»•ng quan

ÄÃ¢y lÃ  3 kiáº¿n trÃºc YOLOv12 Ä‘Æ°á»£c thiáº¿t káº¿ Ä‘áº·c biá»‡t Ä‘á»ƒ phÃ¡t hiá»‡n cÃ¡c Ä‘á»‘i tÆ°á»£ng nhá» trÃªn dataset **Visdrone**. Má»—i kiáº¿n trÃºc cÃ³ Ä‘iá»ƒm máº¡nh riÃªng vÃ  Ä‘Æ°á»£c tá»‘i Æ°u cho cÃ¡c trÆ°á»ng há»£p sá»­ dá»¥ng khÃ¡c nhau.

---

## ğŸ“Š So sÃ¡nh cÃ¡c kiáº¿n trÃºc

| Kiáº¿n trÃºc | Äá»™ phá»©c táº¡p | Tá»‘c Ä‘á»™ | Äá»™ chÃ­nh xÃ¡c | PhÃ¹ há»£p cho |
|-----------|-------------|--------|--------------|-------------|
| **yolo12-visdrone.yaml** | â­â­â­ | âš¡âš¡âš¡âš¡ | ğŸ“ˆğŸ“ˆğŸ“ˆ | CÃ¢n báº±ng tá»‘c Ä‘á»™ & Ä‘á»™ chÃ­nh xÃ¡c |
| **yolo12-visdrone-bifpn.yaml** | â­â­â­â­ | âš¡âš¡âš¡ | ğŸ“ˆğŸ“ˆğŸ“ˆğŸ“ˆ | Äá»™ chÃ­nh xÃ¡c cao, nhiá»u tÃ­nh nÄƒng |
| **yolo12-visdrone-dense.yaml** | â­â­â­â­â­ | âš¡âš¡ | ğŸ“ˆğŸ“ˆğŸ“ˆğŸ“ˆğŸ“ˆ | Äá»‘i tÆ°á»£ng cá»±c nhá», nghiÃªn cá»©u |

---

## ğŸ¯ Kiáº¿n trÃºc 1: yolo12-visdrone.yaml

### Äáº·c Ä‘iá»ƒm chÃ­nh:
- âœ… **P2 Detection Head** (stride 4) - phÃ¡t hiá»‡n Ä‘á»‘i tÆ°á»£ng nhá»
- âœ… **CBAM Attention** trÃªn P2 vÃ  P3 layers
- âœ… **Enhanced FPN** vá»›i top-down vÃ  bottom-up pathways
- âœ… **4 detection scales**: P2/4, P3/8, P4/16, P5/32

### Æ¯u Ä‘iá»ƒm:
- Kiáº¿n trÃºc Ä‘Æ¡n giáº£n, dá»… train
- Tá»‘c Ä‘á»™ inference nhanh
- Hiá»‡u quáº£ vá»›i Ä‘á»‘i tÆ°á»£ng nhá»-trung bÃ¬nh
- CBAM giÃºp táº­p trung vÃ o vÃ¹ng quan trá»ng

### Khi nÃ o sá»­ dá»¥ng:
- âœ… Triá»ƒn khai production vá»›i yÃªu cáº§u real-time
- âœ… GPU/thiáº¿t bá»‹ cÃ³ tÃ i nguyÃªn háº¡n cháº¿
- âœ… Cáº§n cÃ¢n báº±ng giá»¯a tá»‘c Ä‘á»™ vÃ  Ä‘á»™ chÃ­nh xÃ¡c
- âœ… Äá»‘i tÆ°á»£ng nhá» khÃ´ng quÃ¡ extreme (> 16x16 pixels)

### Training command:
```bash
# Training tá»« scratch
yolo detect train data=VisDrone.yaml model=ultralytics/cfg/models/12/yolo12-visdrone.yaml epochs=300 imgsz=1024 batch=16

# Fine-tuning tá»« yolo12 pretrained
yolo detect train data=VisDrone.yaml model=yolo12m.pt cfg=ultralytics/cfg/models/12/yolo12-visdrone.yaml epochs=200 imgsz=1024
```

---

## ğŸš€ Kiáº¿n trÃºc 2: yolo12-visdrone-bifpn.yaml (KHUYáº¾N NGHá»Š)

### Äáº·c Ä‘iá»ƒm chÃ­nh:
- âœ… **BiFPN-inspired connections** - káº¿t ná»‘i Ä‘a chiá»u
- âœ… **C2fPSA** (Polarized Self-Attention) - attention máº¡nh máº½
- âœ… **Multi-source fusion**: Káº¿t há»£p features tá»« nhiá»u nguá»“n
- âœ… **SPPF** (Spatial Pyramid Pooling Fast) - global context
- âœ… **Enhanced P2 pathway** - 3 repeats thay vÃ¬ 2

### Æ¯u Ä‘iá»ƒm:
- BiFPN connections cho phÃ©p information flow tá»‘t hÆ¡n
- PSA attention hiá»‡u quáº£ hÆ¡n CBAM cho small objects
- Multi-source fusion táº­n dá»¥ng features á»Ÿ nhiá»u levels
- SPPF giÃºp náº¯m báº¯t multi-scale context

### Khi nÃ o sá»­ dá»¥ng:
- âœ… **KHUYáº¾N NGHá»Š cho Visdrone**
- âœ… Muá»‘n Ä‘á»™ chÃ­nh xÃ¡c cao nháº¥t cÃ³ thá»ƒ
- âœ… GPU Ä‘á»§ máº¡nh (RTX 3090, 4090, V100, A100)
- âœ… CÃ³ thá»ƒ cháº¥p nháº­n tá»‘c Ä‘á»™ cháº­m hÆ¡n 20-30%
- âœ… Competition, research, hoáº·c offline inference

### Training command:
```bash
# Training vá»›i scale 's' - khuyáº¿n nghá»‹
yolo detect train data=VisDrone.yaml model=ultralytics/cfg/models/12/yolo12-visdrone-bifpn.yaml \
    epochs=300 imgsz=1024 batch=12 scale=s

# Training vá»›i scale 'm' - Ä‘á»™ chÃ­nh xÃ¡c cao
yolo detect train data=VisDrone.yaml model=ultralytics/cfg/models/12/yolo12-visdrone-bifpn.yaml \
    epochs=300 imgsz=1024 batch=8 scale=m optimizer=AdamW lr0=0.001
```

---

## ğŸ’ Kiáº¿n trÃºc 3: yolo12-visdrone-dense.yaml

### Äáº·c Ä‘iá»ƒm chÃ­nh:
- âœ… **Dense connections** - DenseNet-inspired
- âœ… **Cross-scale direct connections** - P2 -> P4 trá»±c tiáº¿p
- âœ… **Dual attention** - Channel + Spatial attention riÃªng biá»‡t
- âœ… **Maximum feature reuse** - táº­n dá»¥ng tá»‘i Ä‘a features
- âœ… **Stride-4 convolution** - P2 to P4 direct path (SÃNG Táº O!)

### Æ¯u Ä‘iá»ƒm:
- Hiá»‡u quáº£ nháº¥t vá»›i Ä‘á»‘i tÆ°á»£ng cá»±c nhá» (< 16x16 pixels)
- Dense connections giáº£m vanishing gradient
- Cross-scale direct paths giá»¯ chi tiáº¿t tá»« resolution cao
- Dual attention mechanism máº¡nh máº½

### NhÆ°á»£c Ä‘iá»ƒm:
- Memory consumption cao nháº¥t
- Tá»‘c Ä‘á»™ cháº­m nháº¥t
- Cáº§n GPU memory lá»›n
- KhÃ³ train hÆ¡n (dá»… overfit)

### Khi nÃ o sá»­ dá»¥ng:
- âœ… Äá»‘i tÆ°á»£ng cá»±c nhá», ráº¥t khÃ³ phÃ¡t hiá»‡n
- âœ… Dataset cÃ³ nhiá»u birds, distant pedestrians
- âœ… NghiÃªn cá»©u, paper, competition
- âœ… GPU memory >= 24GB
- âœ… KhÃ´ng quan tÃ¢m tá»‘c Ä‘á»™ inference
- âœ… Muá»‘n push giá»›i háº¡n cá»§a small object detection

### Training command:
```bash
# Training vá»›i mixed precision Ä‘á»ƒ tiáº¿t kiá»‡m memory
yolo detect train data=VisDrone.yaml model=ultralytics/cfg/models/12/yolo12-visdrone-dense.yaml \
    epochs=300 imgsz=1024 batch=6 scale=s amp=True patience=50

# Training vá»›i scale 'n' náº¿u GPU memory háº¡n cháº¿
yolo detect train data=VisDrone.yaml model=ultralytics/cfg/models/12/yolo12-visdrone-dense.yaml \
    epochs=300 imgsz=896 batch=8 scale=n
```

---

## ğŸ¨ CÃ¡c Ä‘á»•i má»›i sÃ¡ng táº¡o

### 1. **P2 Detection Head**
```yaml
# Táº¥t cáº£ 3 kiáº¿n trÃºc Ä‘á»u cÃ³ P2 head
- P2 (stride 4): PhÃ¡t hiá»‡n Ä‘á»‘i tÆ°á»£ng 16-32 pixels
- P3 (stride 8): PhÃ¡t hiá»‡n Ä‘á»‘i tÆ°á»£ng 32-64 pixels
- P4 (stride 16): PhÃ¡t hiá»‡n Ä‘á»‘i tÆ°á»£ng 64-128 pixels
- P5 (stride 32): PhÃ¡t hiá»‡n Ä‘á»‘i tÆ°á»£ng > 128 pixels
```

### 2. **Multi-source Feature Fusion** (BiFPN architecture)
```yaml
# Káº¿t há»£p features tá»« nhiá»u nguá»“n
- [[-1, 15, 4], 1, Concat, [1]]  # P3_topdown + P3_bottomup + P3_backbone
```

### 3. **Cross-scale Direct Connections** (Dense architecture)
```yaml
# P2 -> P4 trá»±c tiáº¿p (stride 4) - giá»¯ thÃ´ng tin chi tiáº¿t
- [20, 1, Conv, [128, 3, 4]]  # Innovative: skip P3, go directly to P4
```

### 4. **Attention Mechanisms**
- **CBAM**: Channel + Spatial attention (Ä‘Æ¡n giáº£n, hiá»‡u quáº£)
- **PSA**: Polarized Self-Attention (máº¡nh hÆ¡n, phá»©c táº¡p hÆ¡n)
- **C2fAttn**: Attention-enhanced C2f blocks
- **Dual Attention**: Channel vÃ  Spatial riÃªng biá»‡t

---

## ğŸ“‹ Hyperparameters khuyáº¿n nghá»‹ cho Visdrone

### Augmentation cho small objects:
```yaml
# Create visdrone_aug.yaml
hsv_h: 0.015  # Giáº£m Ä‘á»ƒ trÃ¡nh máº¥t object nhá»
hsv_s: 0.5
hsv_v: 0.4
degrees: 0  # KhÃ´ng rotate - objects nhá» dá»… máº¥t
translate: 0.1  # Giáº£m translation
scale: 0.2  # Giáº£m scale Ä‘á»ƒ giá»¯ small objects
shear: 0  # KhÃ´ng shear
perspective: 0  # KhÃ´ng perspective
flipud: 0.0  # KhÃ´ng flip vertical (drones luÃ´n nhÃ¬n tá»« trÃªn)
fliplr: 0.5  # Horizontal flip OK
mosaic: 1.0  # Mosaic tá»‘t cho small objects
mixup: 0.1  # Ãt mixup
copy_paste: 0.0  # KhÃ´ng copy-paste (confuse small objects)
```

### Training hyperparameters:
```yaml
# Recommended settings
imgsz: 1024  # Hoáº·c 1280 náº¿u GPU Ä‘á»§ máº¡nh
batch: 8-16  # TÃ¹y GPU
epochs: 300
patience: 50
optimizer: AdamW  # Tá»‘t hÆ¡n SGD cho small objects
lr0: 0.001  # Learning rate ban Ä‘áº§u
lrf: 0.01  # Final learning rate
momentum: 0.937
weight_decay: 0.0005
warmup_epochs: 5
warmup_momentum: 0.8
box: 7.5  # Box loss gain
cls: 0.5  # Class loss gain (giáº£m vÃ¬ Visdrone imbalanced)
dfl: 1.5  # DFL loss gain
```

---

## ğŸ”§ Tips & Tricks cho Visdrone

### 1. Image Size
- **Khuyáº¿n nghá»‹**: 1024x1024 hoáº·c 1280x1280
- Visdrone cÃ³ nhiá»u objects cá»±c nhá», cáº§n resolution cao
- Náº¿u GPU memory háº¡n cháº¿, tá»‘i thiá»ƒu 896x896

### 2. Multi-scale Training & Testing
```bash
# Training vá»›i multi-scale
yolo detect train data=VisDrone.yaml model=yolo12-visdrone-bifpn.yaml imgsz=1024 scale=0.5

# Testing vá»›i multi-scale TTA (Test Time Augmentation)
yolo detect val model=runs/detect/train/weights/best.pt data=VisDrone.yaml imgsz=1280 augment=True
```

### 3. Confidence & IoU Thresholds
```bash
# Small objects cáº§n thresholds tháº¥p hÆ¡n
yolo detect val model=best.pt conf=0.001 iou=0.3 max_det=1000
```

### 4. NMS (Non-Maximum Suppression)
```bash
# Visdrone cÃ³ nhiá»u objects chá»“ng chÃ©o
yolo detect val model=best.pt iou=0.3 agnostic_nms=True
```

### 5. Class Imbalance
Visdrone cÃ³ class imbalance nghiÃªm trá»ng:
- **Nhiá»u**: car, people, van
- **Ãt**: tricycle, awning-tricycle, bus

Giáº£i phÃ¡p:
```python
# Trong training code, thÃªm class weights
# hoáº·c sá»­ dá»¥ng focal loss
```

---

## ğŸ“ˆ Káº¿t quáº£ ká»³ vá»ng trÃªn Visdrone

### Vá»›i yolo12-visdrone-bifpn.yaml (scale 'm'):
```
Expected mAP50-95: 0.28-0.32
Expected mAP50: 0.48-0.52

Per class (rough estimates):
- Pedestrian: AP50 ~0.42
- People: AP50 ~0.38
- Bicycle: AP50 ~0.28
- Car: AP50 ~0.68
- Van: AP50 ~0.55
- Truck: AP50 ~0.52
- Tricycle: AP50 ~0.32
- Awning-tricycle: AP50 ~0.25
- Bus: AP50 ~0.58
- Motor: AP50 ~0.48
```

---

## ğŸš€ Quick Start

### 1. Chuáº©n bá»‹ dataset Visdrone
```bash
# Download Visdrone dataset
# Organize theo format YOLO
dataset/
  â”œâ”€â”€ train/
  â”‚   â”œâ”€â”€ images/
  â”‚   â””â”€â”€ labels/
  â”œâ”€â”€ val/
  â”‚   â”œâ”€â”€ images/
  â”‚   â””â”€â”€ labels/
  â””â”€â”€ VisDrone.yaml
```

### 2. Chá»n kiáº¿n trÃºc
- **Production/Real-time**: yolo12-visdrone.yaml
- **CÃ¢n báº±ng tá»‘t nháº¥t**: yolo12-visdrone-bifpn.yaml â­
- **Maximum accuracy**: yolo12-visdrone-dense.yaml

### 3. Training
```bash
# VÃ­ dá»¥ vá»›i BiFPN (khuyáº¿n nghá»‹)
yolo detect train \
    data=VisDrone.yaml \
    model=ultralytics/cfg/models/12/yolo12-visdrone-bifpn.yaml \
    epochs=300 \
    imgsz=1024 \
    batch=12 \
    device=0 \
    project=visdrone \
    name=yolo12-bifpn-m \
    scale=m
```

### 4. Validation
```bash
yolo detect val \
    model=visdrone/yolo12-bifpn-m/weights/best.pt \
    data=VisDrone.yaml \
    imgsz=1024 \
    conf=0.001 \
    iou=0.3 \
    max_det=1000
```

### 5. Inference
```bash
yolo detect predict \
    model=visdrone/yolo12-bifpn-m/weights/best.pt \
    source=test_images/ \
    imgsz=1024 \
    conf=0.25 \
    save=True \
    save_txt=True
```

---

## ğŸ”¬ Experiments & Ablation Studies

### Thá»­ nghiá»‡m cÃ¡c variants:

1. **Vá»›i/KhÃ´ng P2 head**
   ```bash
   # So sÃ¡nh mAP cá»§a small objects
   ```

2. **Attention mechanisms**
   - CBAM vs PSA vs None
   - Dual attention (Channel + Spatial) vs Single

3. **FPN variants**
   - Standard FPN
   - BiFPN
   - Dense FPN

4. **Backbone depth**
   - C3k2 repeats: 2 vs 3 vs 4

---

## ğŸ“š References & Inspiration

1. **BiFPN**: "EfficientDet: Scalable and Efficient Object Detection"
2. **PSA**: "Polarized Self-Attention: Towards High-quality Pixel-wise Regression"
3. **CBAM**: "Convolutional Block Attention Module"
4. **Dense Connections**: "Densely Connected Convolutional Networks"
5. **Feature Pyramid**: "Feature Pyramid Networks for Object Detection"

---

## ğŸ¤ Contributing

Náº¿u báº¡n cÃ³ Ã½ tÆ°á»Ÿng cáº£i tiáº¿n hoáº·c káº¿t quáº£ tá»‘t hÆ¡n, hÃ£y chia sáº»!

---

## âš ï¸ LÆ°u Ã½ quan trá»ng

1. **GPU Memory**: Kiáº¿n trÃºc dense cáº§n GPU >= 24GB
2. **Training time**: Vá»›i Visdrone, cáº§n 300+ epochs Ä‘á»ƒ converge
3. **Patience**: Small object detection khÃ³, cáº§n kiÃªn nháº«n tune hyperparameters
4. **Validation**: LuÃ´n validate trÃªn test set riÃªng, khÃ´ng overfit trÃªn val set
5. **Class imbalance**: Xem xÃ©t weighted loss hoáº·c focal loss

---

**ChÃºc báº¡n training thÃ nh cÃ´ng! ğŸš€**

Made with â¤ï¸ for Visdrone small object detection

