# H∆∞·ªõng D·∫´n T√πy Ch·ªânh Ultralytics YOLO - Chi Ti·∫øt To√†n Di·ªán

## üìã T·ªïng Quan

B·∫°n ƒëang s·ª≠ d·ª•ng **Ultralytics v8.3.228** - phi√™n b·∫£n cu·ªëi c√πng h·ªó tr·ª£ YOLO11 (kh√¥ng ph·∫£i YOLO26).

### ‚úÖ Kh·∫£ NƒÉng T√πy Ch·ªânh ƒê∆∞·ª£c H·ªó Tr·ª£

Ultralytics YOLO **c√≥ ƒë·∫ßy ƒë·ªß h·ªó tr·ª£** ƒë·ªÉ t√πy ch·ªânh:
- ‚úÖ **Backbone** - Thay ƒë·ªïi ki·∫øn tr√∫c chi·∫øt xu·∫•t ƒë·∫∑c tr∆∞ng
- ‚úÖ **Neck** - S·ª≠a ƒë·ªïi k·∫øt n·ªëi gi·ªØa backbone v√† head
- ‚úÖ **Loss Functions** - Thay ƒë·ªïi c√°c h√†m m·∫•t m√°t
- ‚úÖ **Activation Functions** - T√πy ch·ªânh h√†m k√≠ch ho·∫°t
- ‚úÖ **Modules** - T·∫°o ho·∫∑c thay th·∫ø c√°c m√¥-ƒëun t√πy ch·ªânh

---

## üèóÔ∏è Ph·∫ßn 1: Hi·ªÉu C·∫•u Tr√∫c Ki·∫øn Tr√∫c YOLO

### 1.1 C·∫•u Tr√∫c T·ªáp YAML

M·ªói m√¥ h√¨nh YOLO ƒë∆∞·ª£c ƒë·ªãnh nghƒ©a b·∫±ng file YAML c√≥ ba ph·∫ßn ch√≠nh:

```yaml
# V√≠ d·ª•: ultralytics/cfg/models/11/yolo11.yaml

nc: 80  # S·ªë l·ªõp
scales:  # H·ªá s·ªë t·ª∑ l·ªá m√¥ h√¨nh
  n: [0.50, 0.25, 1024]  # [depth_multiple, width_multiple, max_channels]
  s: [0.50, 0.50, 1024]
  m: [0.50, 1.00, 512]
  l: [1.00, 1.00, 512]
  x: [1.00, 1.50, 512]

# PH·∫¶N BACKBONE - Chi·∫øt xu·∫•t ƒë·∫∑c tr∆∞ng
backbone:
  # [from, repeats, module, args]
  - [-1, 1, Conv, [64, 3, 2]]          # Layer 0: Convolution
  - [-1, 1, Conv, [128, 3, 2]]         # Layer 1: Downsample
  - [-1, 2, C3k2, [256, False, 0.25]]  # Layer 2: Repeated block
  - [-1, 1, Conv, [256, 3, 2]]         # Layer 3
  - [-1, 2, C3k2, [512, False, 0.25]]  # Layer 4
  - [-1, 1, SPPF, [1024, 5]]           # Layer 9: Spatial Pyramid Pooling

# PH·∫¶N NECK - K·∫øt n·ªëi v√† t·ªïng h·ª£p ƒë·∫∑c tr∆∞ng
head:
  - [-1, 1, nn.Upsample, [None, 2, "nearest"]]  # Upsample
  - [[-1, 6], 1, Concat, [1]]                   # Concatenate with skip connection
  - [-1, 2, C3k2, [512, False]]                 # Process merged features
  
  # L·∫∑p l·∫°i cho c√°c t·ª∑ l·ªá kh√°c nhau
  - [-1, 1, Conv, [256, 3, 2]]
  - [[-1, 13], 1, Concat, [1]]
  - [-1, 2, C3k2, [512, False]]
  
  # PH·∫¶N HEAD - Ph√°t hi·ªán ƒë·ªëi t∆∞·ª£ng
  - [[16, 19, 22], 1, Detect, [nc]]  # Detect layer cho c·∫£ 3 t·ª∑ l·ªá
```

### 1.2 ƒê·ªãnh D·∫°ng L·ªõp: [from, repeats, module, args]

| Th√†nh ph·∫ßn | √ù Nghƒ©a | V√≠ D·ª• |
|-----------|---------|-------|
| **from** | K·∫øt n·ªëi t·ª´ layer n√†o | `-1` (layer tr∆∞·ªõc), `6` (layer 6), `[4,6,8]` (multiple inputs) |
| **repeats** | L·∫∑p l·∫°i bao nhi√™u l·∫ßn | `1` (m·ªôt l·∫ßn), `3` (ba l·∫ßn), `2` (hai l·∫ßn) |
| **module** | Lo·∫°i m√¥-ƒëun | `Conv`, `C2f`, `C3k2`, `SPPF`, `Detect` |
| **args** | C√°c tham s·ªë m√¥-ƒëun | `[64, 3, 2]` (channels, kernel_size, stride) |

---

## üîß Ph·∫ßn 2: T√πy Ch·ªânh Backbone

### 2.1 C√°ch Thay ƒê·ªïi Backbone

**Ph∆∞∆°ng ph√°p A: T·∫°o file YAML t√πy ch·ªânh**

```yaml
# custom_backbone.yaml
nc: 80

backbone:
  # Thay th·∫ø backbone YOLO11 b·∫±ng c√°c layer t√πy ch·ªânh
  - [-1, 1, Conv, [32, 3, 1]]
  - [-1, 1, Conv, [64, 3, 2]]          # P1/2
  - [-1, 1, Conv, [128, 3, 2]]         # P2/4
  - [-1, 3, C2f, [128, True]]          # S·ª≠ d·ª•ng C2f block
  - [-1, 1, Conv, [256, 3, 2]]         # P3/8
  - [-1, 6, C2f, [256, True]]          # Nhi·ªÅu block h∆°n
  - [-1, 1, Conv, [512, 3, 2]]         # P4/16
  - [-1, 6, C2f, [512, True]]
  - [-1, 1, Conv, [1024, 3, 2]]        # P5/32
  - [-1, 3, C2f, [1024, True]]
  - [-1, 1, SPPF, [1024, 5]]           # Spatial Pyramid Pooling - FAST

head:
  # S·ª≠ d·ª•ng head ti√™u chu·∫©n
  - [-1, 1, nn.Upsample, [None, 2, "nearest"]]
  - [[-1, 6], 1, Concat, [1]]
  - [-1, 3, C2f, [512]]
  
  - [-1, 1, nn.Upsample, [None, 2, "nearest"]]
  - [[-1, 4], 1, Concat, [1]]
  - [-1, 3, C2f, [256]]
  
  - [-1, 1, Conv, [256, 3, 2]]
  - [[-1, 12], 1, Concat, [1]]
  - [-1, 3, C2f, [512]]
  
  - [-1, 1, Conv, [512, 3, 2]]
  - [[-1, 9], 1, Concat, [1]]
  - [-1, 3, C2f, [1024]]
  
  - [[15, 18, 21], 1, Detect, [nc]]
```

### 2.2 C√°c M√¥-ƒëun Backbone C√≥ S·∫µn

C√°c m√¥-ƒëun b·∫°n c√≥ th·ªÉ s·ª≠ d·ª•ng trong backbone:

**Convolution blocks:**
- `Conv` - Conv2d + BatchNorm + Activation
- `Conv2` - Depthwise separable convolution
- `DWConv` - Depthwise convolution
- `Focus` - Focus layer (input preprocessing)
- `GhostConv` - Ghost convolution (lightweight)

**Bottleneck blocks:**
- `Bottleneck` - Inverted bottleneck
- `BottleneckCSP` - CSP bottleneck
- `C2f` - CSPDarknet block (YOLO11 ti√™u chu·∫©n)
- `C2fAttn` - C2f v·ªõi attention
- `C3k2` - YOLO11 variant
- `RepConv` - Reparameterized convolution

**Pooling layers:**
- `SPPF` - Spatial Pyramid Pooling - Fast
- `SPP` - Spatial Pyramid Pooling
- `ImagePoolingAttn` - Image pooling attention

**Kh√°c:**
- `ResNetLayer` - ResNet layer
- `HGStem` - HG Stem layer
- `HGBlock` - HG Block layer

### 2.3 S·ª≠ D·ª•ng Backbone t·ª´ TorchVision

```yaml
# torchvision_backbone.yaml
nc: 80

backbone:
  # S·ª≠ d·ª•ng ConvNeXt t·ª´ TorchVision
  - [-1, 1, TorchVision, [768, convnext_tiny, DEFAULT, True, 2, True]]
  #                       [channels, model_name, pretrained, train_layers, layer_indices]

head:
  - [0, 1, Index, [192, 4]]   # P3 features
  - [0, 1, Index, [384, 6]]   # P4 features
  - [0, 1, Index, [768, 8]]   # P5 features
  - [[1, 2, 3], 1, Detect, [nc]]
```

---

## üîå Ph·∫ßn 3: T√πy Ch·ªânh Neck

### 3.1 Neck l√† g√¨?

**Neck** (c·ªï) k·∫øt n·ªëi backbone v·ªõi head, th∆∞·ªùng bao g·ªìm:
- Upsampling layers ƒë·ªÉ m·ªü r·ªông l·∫°i k√≠ch th∆∞·ªõc
- Concatenation ƒë·ªÉ k·∫øt h·ª£p ƒë·∫∑c tr∆∞ng t·ª´ nhi·ªÅu t·ª∑ l·ªá
- Processing blocks ƒë·ªÉ x·ª≠ l√Ω c√°c ƒë·∫∑c tr∆∞ng h·ª£p nh·∫•t

### 3.2 V√≠ D·ª•: T√πy Ch·ªânh Neck

```yaml
# custom_neck.yaml
backbone:
  # L·∫•y t·ª´ YOLO11 standard
  - [-1, 1, Conv, [64, 3, 2]]
  - [-1, 1, Conv, [128, 3, 2]]
  - [-1, 2, C3k2, [256, False, 0.25]]
  - [-1, 1, Conv, [256, 3, 2]]          # Layer 3
  - [-1, 2, C3k2, [512, False, 0.25]]  # Layer 4
  - [-1, 1, Conv, [512, 3, 2]]          # Layer 5
  - [-1, 2, C3k2, [512, True]]          # Layer 6
  - [-1, 1, Conv, [1024, 3, 2]]         # Layer 7
  - [-1, 2, C3k2, [1024, True]]         # Layer 8
  - [-1, 1, SPPF, [1024, 5]]            # Layer 9

head:
  # NECK - Custom upsampling path v·ªõi nhi·ªÅu processing
  - [-1, 1, Conv, [512, 1, 1]]          # Layer 10: Reduce channels
  - [-1, 1, nn.Upsample, [None, 2, "nearest"]]
  - [[-1, 6], 1, Concat, [1]]           # Skip connection t·ª´ backbone layer 6
  - [-1, 3, C2f, [512]]                 # Layer 13: Intensive processing
  
  - [-1, 1, Conv, [256, 1, 1]]
  - [-1, 1, nn.Upsample, [None, 2, "nearest"]]
  - [[-1, 4], 1, Concat, [1]]           # Skip connection t·ª´ backbone layer 4
  - [-1, 3, C2f, [256]]                 # Layer 16
  
  # Downsampling path - t∆∞∆°ng t·ª± nh∆∞ng ng∆∞·ª£c l·∫°i
  - [-1, 1, Conv, [256, 3, 2]]
  - [[-1, 13], 1, Concat, [1]]
  - [-1, 3, C2f, [512]]                 # Layer 19
  
  - [-1, 1, Conv, [512, 3, 2]]
  - [[-1, 10], 1, Concat, [1]]
  - [-1, 3, C2f, [1024]]                # Layer 22
  
  # HEAD - Detection
  - [[16, 19, 22], 1, Detect, [nc]]
```

### 3.3 C·∫•p Cao: S·ª≠ D·ª•ng Attention trong Neck

```yaml
# attention_neck.yaml
backbone:
  # ... backbone layers ...
  - [-1, 1, SPPF, [1024, 5]]

head:
  - [-1, 1, nn.Upsample, [None, 2, "nearest"]]
  - [[-1, 6], 1, Concat, [1]]
  - [-1, 2, C2fAttn, [512, 256, 8]]      # C2f v·ªõi attention (channels, embed_dim, heads)
  
  - [-1, 1, nn.Upsample, [None, 2, "nearest"]]
  - [[-1, 4], 1, Concat, [1]]
  - [-1, 2, C2fAttn, [256, 128, 8]]
  
  # Rest of head...
  - [[final_layer_indices], 1, Detect, [nc]]
```

---

## üíî Ph·∫ßn 4: Thay ƒê·ªïi Loss Functions

### 4.1 Loss Functions C√≥ S·∫µn

Ultralytics cung c·∫•p c√°c loss functions c√≥ s·∫µn:

**Cho Detection (trong `ultralytics/utils/loss.py`):**

```python
class v8DetectionLoss:
    """YOLOv8 Detection Loss"""
    # Th√†nh ph·∫ßn:
    # - BCE Loss cho classification
    # - IoU Loss (CIoU) cho bounding boxes
    # - DFL Loss cho distribution focal loss

class VarifocalLoss(nn.Module):
    """Varifocal Loss - x·ª≠ l√Ω class imbalance"""
    # Tham s·ªë: gamma (focusing), alpha (balancing)

class FocalLoss(nn.Module):
    """Focal Loss - down-weight easy examples"""

class BboxLoss(nn.Module):
    """Bounding Box Loss v·ªõi DFL"""

class DFLoss(nn.Module):
    """Distribution Focal Loss"""
```

### 4.2 C√°ch Thay ƒê·ªïi Loss Function

**B∆∞·ªõc 1: T·∫°o Custom Loss Class**

```python
# custom_loss.py
import torch
import torch.nn as nn
import torch.nn.functional as F

class CustomDetectionLoss:
    """Custom Detection Loss cho research"""
    
    def __init__(self, model, tal_topk=10):
        device = next(model.parameters()).device
        h = model.args
        m = model.model[-1]  # Detect module
        
        self.bce = nn.BCEWithLogitsLoss(reduction="none")
        self.hyp = h
        self.stride = m.stride
        self.nc = m.nc
        self.reg_max = m.reg_max
        self.device = device
        
        # Import c·∫ßn thi·∫øt t·ª´ ultralytics
        from ultralytics.utils.tal import TaskAlignedAssigner
        from ultralytics.utils.loss import BboxLoss
        
        self.assigner = TaskAlignedAssigner(topk=tal_topk, num_classes=self.nc)
        self.bbox_loss = BboxLoss(m.reg_max).to(device)
    
    def __call__(self, preds, batch):
        """Compute custom loss"""
        # preds: model predictions
        # batch: ground truth batch
        
        # Implement your custom loss computation
        # ...
        
        loss = torch.zeros(3, device=self.device)  # [box, cls, dfl]
        
        # Your implementation
        # loss[0] = box_loss
        # loss[1] = cls_loss
        # loss[2] = dfl_loss
        
        return loss * batch_size, loss.detach()
```

**B∆∞·ªõc 2: Override init_criterion trong Model**

```python
# models/yolo/detect/train.py ho·∫∑c custom trainer

from ultralytics.models.yolo.detect.train import DetectionTrainer
from ultralytics.nn.tasks import DetectionModel

class CustomDetectionModel(DetectionModel):
    def init_criterion(self):
        """Initialize custom loss criterion"""
        from custom_loss import CustomDetectionLoss
        return CustomDetectionLoss(self)

class CustomDetectionTrainer(DetectionTrainer):
    def get_model(self, cfg=None, weights=None, verbose=True):
        """Return custom detection model"""
        model = CustomDetectionModel(cfg or self.args.model, ch=3, nc=self.data["nc"], verbose=verbose)
        if weights:
            model.load(weights)
        return model
```

**B∆∞·ªõc 3: S·ª≠ D·ª•ng trong Training**

```python
# train_custom.py
from custom_trainer import CustomDetectionTrainer
from ultralytics import YOLO

# C√°ch 1: S·ª≠ d·ª•ng tr·ª±c ti·∫øp v·ªõi command line
# yolo detect train model=yolo11n.yaml data=coco8.yaml epochs=100 trainer=CustomDetectionTrainer

# C√°ch 2: S·ª≠ d·ª•ng trong Python
trainer = CustomDetectionTrainer(
    cfg=dict(model="yolo11n.yaml", data="coco8.yaml", epochs=100),
    overrides={}
)
trainer.train()
```

### 4.3 Hi·ªÉu Loss Components

```python
# v8DetectionLoss breakdown
def __call__(self, preds, batch):
    """
    preds: [pred_scores, pred_dist, pred_bboxes] t·ª´ model
    batch: {img, bboxes, cls, ...} ground truth
    """
    
    # 1. Task Aligned Assignment - x√°c ƒë·ªãnh positive/negative samples
    target_scores, target_bboxes, fg_mask = self.assigner(...)
    
    # 2. Classification Loss (BCE)
    loss_cls = self.bce(pred_scores, target_scores).sum() / target_scores.sum()
    
    # 3. Bbox Regression Loss
    loss_iou = self.bbox_loss.compute_iou(pred_bboxes, target_bboxes)
    
    # 4. Distribution Focal Loss (DFL)
    loss_dfl = self.bbox_loss.dfl_loss(pred_dist, target_dist)
    
    # 5. Weighted combination
    total_loss = (
        self.hyp.box * loss_iou +
        self.hyp.cls * loss_cls +
        self.hyp.dfl * loss_dfl
    )
    
    return total_loss
```

### 4.4 Loss Weight Hyperparameters

```yaml
# Trong data YAML ho·∫∑c training config
box: 7.5      # Bounding box loss weight
cls: 0.5      # Classification loss weight
dfl: 1.5      # DFL loss weight (cho distribution)
```

---

## ‚ö° Ph·∫ßn 5: Thay ƒê·ªïi Activation Functions

### 5.1 Activation Functions M·∫∑c ƒê·ªãnh

YOLO11 s·ª≠ d·ª•ng **SiLU (Swish)** l√†m default activation.

### 5.2 Thay ƒê·ªïi Activation

**Ph∆∞∆°ng ph√°p A: Trong YAML**

```yaml
# custom_model.yaml
activation: torch.nn.ReLU()  # Ho·∫∑c b·∫•t k·ª≥ activation n√†o

backbone:
  - [-1, 1, Conv, [64, 3, 2]]
  # ... rest of architecture ...
```

**Ph∆∞∆°ng ph√°p B: Thay ƒê·ªïi To√†n C·ª•c**

```python
# Trong training script
from ultralytics.nn.modules import Conv

# Thay ƒë·ªïi default activation
Conv.default_act = torch.nn.ReLU()

# Sau ƒë√≥ load model
model = YOLO("yolo11n.yaml")
```

**Ph∆∞∆°ng ph√°p C: Custom Activation Classes**

```python
# K·∫øt h·ª£p nhi·ªÅu activation
class CustomActivation(nn.Module):
    def __init__(self):
        super().__init__()
        self.silu = nn.SiLU()
        self.relu = nn.ReLU()
    
    def forward(self, x):
        return self.silu(x) * 0.5 + self.relu(x) * 0.5

# S·ª≠ d·ª•ng trong model
Conv.default_act = CustomActivation()
```

---

## üìù Ph·∫ßn 6: T·∫°o Custom Modules

### 6.1 C∆° B·∫£n v·ªÅ Module Registration

```python
# ultralytics/nn/modules/__init__.py
# C√°c modules ƒë∆∞·ª£c t·ª± ƒë·ªông import v√† ƒëƒÉng k√Ω

# ƒê·ªÉ th√™m custom module:
# 1. T·∫°o module trong modules/
# 2. Import trong __init__.py
# 3. S·ª≠ d·ª•ng trong YAML
```

### 6.2 T·∫°o Custom Module

```python
# ultralytics/nn/modules/custom_module.py

import torch
import torch.nn as nn
from ..modules import Conv, C2f

class CustomBlock(nn.Module):
    """Custom feature extraction block"""
    
    def __init__(self, c1, c2, n=1, shortcut=False):
        """
        Args:
            c1: input channels
            c2: output channels
            n: number of blocks
            shortcut: use skip connection
        """
        super().__init__()
        self.cv1 = Conv(c1, c2, 3)
        self.cv2 = Conv(c2, c2, 3)
        self.add = shortcut and c1 == c2
    
    def forward(self, x):
        return x + self.cv2(self.cv1(x)) if self.add else self.cv2(self.cv1(x))

# ƒêƒÉng k√Ω trong __init__.py
from .custom_module import CustomBlock
```

### 6.3 S·ª≠ D·ª•ng Custom Module trong YAML

```yaml
# custom_architecture.yaml
nc: 80

backbone:
  - [-1, 1, Conv, [64, 3, 2]]
  - [-1, 3, CustomBlock, [256, True]]    # S·ª≠ d·ª•ng custom block
  - [-1, 1, Conv, [512, 3, 2]]
  - [-1, 1, SPPF, [1024, 5]]

head:
  # ... head layers ...
```

---

## üéØ Ph·∫ßn 7: H∆∞·ªõng D·∫´n Cho Nghi√™n C·ª©u & Paper

### 7.1 Qui Tr√¨nh T·ªëi ∆Øu Ki·∫øn Tr√∫c

```
1. B·ªé ƒê·ªÄ NGHI√äN C·ª®U (Research Proposal)
   ‚îú‚îÄ X√°c ƒë·ªãnh v·∫•n ƒë·ªÅ c·∫ßn gi·∫£i quy·∫øt
   ‚îú‚îÄ ƒê·ªÅ xu·∫•t c·∫£i ti·∫øn (backbone/neck/loss)
   ‚îî‚îÄ Thi·∫øt l·∫≠p baseline

2. T·∫†O C·∫§U H√åNH YAML
   ‚îú‚îÄ Sao ch√©p t·ª´ yolo11.yaml ho·∫∑c template
   ‚îú‚îÄ Thay ƒë·ªïi backbone/neck
   ‚îú‚îÄ Ghi ch√∫ c√°c thay ƒë·ªïi
   ‚îî‚îÄ ƒê·∫∑t t√™n c√≥ nghƒ©a: custom_resnet_backbone.yaml

3. TH·ª∞C HI·ªÜN THAY ƒê·ªîI CODE
   ‚îú‚îÄ Custom Loss function (n·∫øu c·∫ßn)
   ‚îú‚îÄ Custom Module (n·∫øu c·∫ßn)
   ‚îú‚îÄ Custom Trainer (n·∫øu c·∫ßn)
   ‚îî‚îÄ Ki·ªÉm tra import ƒë√∫ng

4. TRAINING & EVALUATION
   ‚îú‚îÄ Train v·ªõi baseline
   ‚îú‚îÄ Train v·ªõi proposal
   ‚îú‚îÄ So s√°nh metrics (mAP, FPS, parameters)
   ‚îî‚îÄ Ghi l·∫°i k·∫øt qu·∫£

5. L·∫¨P B√ÅOC√ÅO
   ‚îú‚îÄ Architecture diagrams
   ‚îú‚îÄ B·∫£ng so s√°nh k·∫øt qu·∫£
   ‚îú‚îÄ Ph√¢n t√≠ch th·ªùi gian & memory
   ‚îî‚îÄ K·∫øt lu·∫≠n & h∆∞·ªõng ph√°t tri·ªÉn
```

### 7.2 Template: S√°ng T·∫°o Ki·∫øn Tr√∫c T·ªëi ∆Øu

```yaml
# research_optimized_yolo.yaml
# ƒê·ªÅ xu·∫•t: Backbone l·∫π h∆°n + Neck b·∫±ng attention + Loss t·ªëi ∆∞u

nc: 80
scales:
  n: [0.33, 0.25, 1024]
  s: [0.33, 0.50, 1024]

# BACKBONE: Lightweight with Ghost convolutions
backbone:
  - [-1, 1, Conv, [64, 3, 2]]
  - [-1, 1, Conv, [128, 3, 2]]
  - [-1, 2, GhostBottleneck, [128, 128, 3]]     # Ghost block ti·∫øt ki·ªám
  - [-1, 1, Conv, [256, 3, 2]]
  - [-1, 3, C2f, [256, True]]
  - [-1, 1, Conv, [512, 3, 2]]
  - [-1, 3, C2f, [512, True]]
  - [-1, 1, Conv, [1024, 3, 2]]
  - [-1, 2, C2f, [1024, True]]
  - [-1, 1, SPPF, [1024, 5]]

# NECK: Enhanced with Attention
head:
  - [-1, 1, nn.Upsample, [None, 2, "nearest"]]
  - [[-1, 6], 1, Concat, [1]]
  - [-1, 2, C2fAttn, [512, 256, 8]]     # Attention mechanism
  
  - [-1, 1, nn.Upsample, [None, 2, "nearest"]]
  - [[-1, 4], 1, Concat, [1]]
  - [-1, 2, C2fAttn, [256, 128, 8]]
  
  - [-1, 1, Conv, [256, 3, 2]]
  - [[-1, 12], 1, Concat, [1]]
  - [-1, 2, C2f, [512]]
  
  - [-1, 1, Conv, [512, 3, 2]]
  - [[-1, 9], 1, Concat, [1]]
  - [-1, 2, C2f, [1024]]
  
  - [[15, 18, 21], 1, Detect, [nc]]
```

### 7.3 Script Training Cho Nghi√™n C·ª©u

```python
# train_research.py
import torch
from ultralytics import YOLO
from pathlib import Path

# C·∫•u h√¨nh th√≠ nghi·ªám
EXPERIMENTS = {
    "baseline": "yolo11n.yaml",
    "custom_backbone": "research_optimized_yolo.yaml",
    "custom_loss": "yolo11n.yaml",  # v·ªõi custom loss trainer
}

RESULTS = {}

for exp_name, config in EXPERIMENTS.items():
    print(f"\n{'='*60}")
    print(f"Experiment: {exp_name}")
    print(f"{'='*60}")
    
    # Load model
    model = YOLO(config)
    
    # Train
    results = model.train(
        data="coco8.yaml",
        epochs=100,
        imgsz=640,
        batch=16,
        device=0,
        patience=20,
        save=True,
        project="runs/research",
        name=exp_name,
    )
    
    # Validate
    metrics = model.val()
    
    # Store results
    RESULTS[exp_name] = {
        "mAP50": metrics.box.map50,
        "mAP50-95": metrics.box.map,
        "params": sum(p.numel() for p in model.parameters()),
        "speed": metrics.speed['inference']  # ms
    }
    
    # Predict
    predictions = model.predict("test_image.jpg", conf=0.25)

# So s√°nh k·∫øt qu·∫£
print("\n" + "="*60)
print("RESULTS COMPARISON")
print("="*60)

for name, metrics in RESULTS.items():
    print(f"\n{name}:")
    for k, v in metrics.items():
        print(f"  {k}: {v:.4f}")
```

### 7.4 Metrics ƒê·ªÉ Ghi L·∫°i

```python
# Metrics c·∫ßn collect cho paper

metrics_to_track = {
    "Accuracy": ["mAP@0.5", "mAP@0.75", "mAP@0.5-0.95"],
    "Performance": ["FPS", "inference_time_ms", "throughput"],
    "Model Size": ["parameters", "model_size_MB", "FLOPs"],
    "Training": ["total_time", "convergence_epoch", "memory_usage_GB"],
    "Efficiency": ["params_per_mAP", "FLOPs_per_inference"],
}

# T√≠nh to√°n efficiency metrics
def calculate_efficiency(mAP, params, FLOPs):
    return {
        "mAP_per_M_params": mAP / (params / 1e6),
        "mAP_per_G_FLOPs": mAP / (FLOPs / 1e9),
    }
```

### 7.5 Visualization cho Paper

```python
# visualization.py
import matplotlib.pyplot as plt
import numpy as np

def plot_architecture_comparison(results):
    """V·∫Ω bi·ªÉu ƒë·ªì so s√°nh ki·∫øn tr√∫c"""
    fig, axes = plt.subplots(2, 2, figsize=(12, 10))
    
    names = list(results.keys())
    mAP = [results[n]['mAP50-95'] for n in names]
    params = [results[n]['params']/1e6 for n in names]  # M params
    fps = [1000/results[n]['speed'] for n in names]     # FPS
    
    # Plot 1: mAP vs Parameters
    axes[0, 0].scatter(params, mAP, s=100)
    for i, name in enumerate(names):
        axes[0, 0].annotate(name, (params[i], mAP[i]))
    axes[0, 0].set_xlabel("Parameters (M)")
    axes[0, 0].set_ylabel("mAP@0.5-0.95")
    axes[0, 0].set_title("Accuracy vs Model Size")
    
    # Plot 2: mAP vs FPS
    axes[0, 1].scatter(fps, mAP, s=100, c='red')
    for i, name in enumerate(names):
        axes[0, 1].annotate(name, (fps[i], mAP[i]))
    axes[0, 1].set_xlabel("FPS")
    axes[0, 1].set_ylabel("mAP@0.5-0.95")
    axes[0, 1].set_title("Accuracy vs Speed")
    
    # Plot 3: Bar chart - mAP
    axes[1, 0].bar(names, mAP, color='skyblue')
    axes[1, 0].set_ylabel("mAP@0.5-0.95")
    axes[1, 0].set_title("Mean Average Precision")
    
    # Plot 4: Bar chart - Parameters
    axes[1, 1].bar(names, params, color='lightcoral')
    axes[1, 1].set_ylabel("Parameters (M)")
    axes[1, 1].set_title("Model Parameters")
    
    plt.tight_layout()
    plt.savefig("architecture_comparison.png", dpi=300, bbox_inches='tight')
    plt.show()

plot_architecture_comparison(RESULTS)
```

---

## üöÄ Ph·∫ßn 8: V√≠ D·ª• Th·ª±c T·∫ø To√†n B·ªô

### 8.1 V√≠ D·ª• ƒê·∫ßy ƒê·ªß: Backbone T·ªëi ∆Øu

```python
# backbone_optimization_research.py
"""
Research: Lightweight YOLO backbone using MobileNet-inspired blocks
Objective: Gi·∫£m parameters 30% trong khi duy tr√¨ accuracy 95% so v·ªõi baseline
"""

import torch
import torch.nn as nn
from ultralytics import YOLO
from ultralytics.nn.modules import Conv, C2f, SPPF
from ultralytics.models.yolo.detect.train import DetectionTrainer
from ultralytics.nn.tasks import DetectionModel

# 1. Define custom lightweight backbone module
class MobileNetBlock(nn.Module):
    def __init__(self, c1, c2, kernel=3, stride=1, groups=1):
        super().__init__()
        self.dw = nn.Conv2d(c1, c1, kernel, stride, (kernel-1)//2, groups=c1, bias=False)
        self.bn1 = nn.BatchNorm2d(c1)
        self.pw = nn.Conv2d(c1, c2, 1, 1, 0, bias=False)
        self.bn2 = nn.BatchNorm2d(c2)
        self.silu = nn.SiLU(inplace=True)
    
    def forward(self, x):
        x = self.silu(self.bn1(self.dw(x)))
        x = self.silu(self.bn2(self.pw(x)))
        return x

# 2. Register custom module
import ultralytics.nn.modules as modules
modules.MobileNetBlock = MobileNetBlock

# 3. Create YAML config
yaml_content = """
# Lightweight YOLO with MobileNet backbone
nc: 80
scales:
  n: [0.33, 0.25, 1024]
  s: [0.33, 0.50, 1024]

backbone:
  - [-1, 1, Conv, [32, 3, 2]]
  - [-1, 1, MobileNetBlock, [64]]
  - [-1, 1, Conv, [64, 3, 2]]
  - [-1, 2, MobileNetBlock, [128]]
  - [-1, 1, Conv, [128, 3, 2]]
  - [-1, 2, MobileNetBlock, [256]]
  - [-1, 1, Conv, [256, 3, 2]]
  - [-1, 2, MobileNetBlock, [512]]
  - [-1, 1, Conv, [512, 3, 2]]
  - [-1, 1, MobileNetBlock, [1024]]
  - [-1, 1, SPPF, [1024, 5]]

head:
  - [-1, 1, nn.Upsample, [None, 2, "nearest"]]
  - [[-1, 7], 1, Concat, [1]]
  - [-1, 2, C2f, [512]]
  
  - [-1, 1, nn.Upsample, [None, 2, "nearest"]]
  - [[-1, 5], 1, Concat, [1]]
  - [-1, 2, C2f, [256]]
  
  - [-1, 1, Conv, [256, 3, 2]]
  - [[-1, 12], 1, Concat, [1]]
  - [-1, 2, C2f, [512]]
  
  - [-1, 1, Conv, [512, 3, 2]]
  - [[-1, 10], 1, Concat, [1]]
  - [-1, 2, C2f, [1024]]
  
  - [[15, 18, 21], 1, Detect, [nc]]
"""

with open("mobile_yolo.yaml", "w") as f:
    f.write(yaml_content)

# 4. Train
if __name__ == "__main__":
    # Baseline
    print("Training BASELINE (YOLOv11n)")
    model_baseline = YOLO("yolo11n.yaml")
    results_baseline = model_baseline.train(
        data="coco8.yaml",
        epochs=10,
        imgsz=640,
        batch=16,
        project="runs/research",
        name="baseline",
    )
    
    # Proposed
    print("\nTraining PROPOSED (Mobile YOLO)")
    model_mobile = YOLO("mobile_yolo.yaml")
    results_mobile = model_mobile.train(
        data="coco8.yaml",
        epochs=10,
        imgsz=640,
        batch=16,
        project="runs/research",
        name="mobile",
    )
    
    # Compare
    print("\n" + "="*60)
    print("COMPARISON RESULTS")
    print("="*60)
    params_baseline = sum(p.numel() for p in model_baseline.parameters())
    params_mobile = sum(p.numel() for p in model_mobile.parameters())
    reduction = (1 - params_mobile/params_baseline) * 100
    
    print(f"Baseline parameters: {params_baseline/1e6:.1f}M")
    print(f"Mobile parameters: {params_mobile/1e6:.1f}M")
    print(f"Reduction: {reduction:.1f}%")
```

---

## üîç Ph·∫ßn 9: Debugging & Best Practices

### 9.1 Ki·ªÉm Tra Ki·∫øn Tr√∫c

```python
# Visualize model architecture
model = YOLO("custom_model.yaml")
model.model.info()

# Print detailed layer information
from ultralytics.utils.torch_utils import model_info
model_info(model.model)
```

### 9.2 Common Issues & Solutions

| Issue | Solution |
|-------|----------|
| Channel mismatch | Ki·ªÉm tra output channels c·ªßa layer tr∆∞·ªõc ph·∫£i kh·ªõp input channels |
| Model qu√° l·ªõn | Gi·∫£m width_multiple ho·∫∑c channel sizes |
| Out of memory | Gi·∫£m batch size ho·∫∑c imgsz |
| Loss kh√¥ng gi·∫£m | Ki·ªÉm tra learning rate, data loading, loss computation |
| Shapes kh√¥ng kh·ªõp | X√°c nh·∫≠n layer output shapes qua `model.model.info()` |

### 9.3 Performance Profiling

```python
# Profile model performance
import time
import torch
from fvcore.nn import FlopCounterMode

model = YOLO("custom_model.yaml")

# Measure inference time
x = torch.randn(1, 3, 640, 640)
start = time.time()
for _ in range(100):
    _ = model(x)
print(f"Inference time: {(time.time() - start) / 100:.4f}s")

# Calculate FLOPs
flops = FlopCounterMode(model.model).total() / 1e9
print(f"FLOPs: {flops:.2f}B")

# Model size
params = sum(p.numel() for p in model.parameters())
print(f"Parameters: {params / 1e6:.2f}M")
```

---

## üìö Ph·∫ßn 10: T√†i Li·ªáu Tham Kh·∫£o

### C·∫•u Tr√∫c Th∆∞ M·ª•c Ultralytics

```
ultralytics/
‚îú‚îÄ‚îÄ cfg/
‚îÇ   ‚îú‚îÄ‚îÄ default.yaml              # Default config
‚îÇ   ‚îú‚îÄ‚îÄ models/                   # Model YAML definitions
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ 11/                   # YOLO11 configs
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ v8/                   # YOLOv8 configs
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ ...
‚îÇ   ‚îî‚îÄ‚îÄ datasets/                 # Dataset configs
‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îú‚îÄ‚îÄ augment.py                # Data augmentation
‚îÇ   ‚îî‚îÄ‚îÄ dataset.py                # Dataset classes
‚îú‚îÄ‚îÄ engine/
‚îÇ   ‚îú‚îÄ‚îÄ trainer.py                # Base trainer
‚îÇ   ‚îú‚îÄ‚îÄ predictor.py              # Predictor
‚îÇ   ‚îî‚îÄ‚îÄ validator.py              # Validator
‚îú‚îÄ‚îÄ models/
‚îÇ   ‚îú‚îÄ‚îÄ yolo/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ detect/               # Detection task
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ segment/              # Segmentation task
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ classify/             # Classification task
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ pose/                 # Pose estimation
‚îÇ   ‚îî‚îÄ‚îÄ ...
‚îú‚îÄ‚îÄ nn/
‚îÇ   ‚îú‚îÄ‚îÄ modules/                  # Network modules
‚îÇ   ‚îú‚îÄ‚îÄ tasks.py                  # Task definitions
‚îÇ   ‚îî‚îÄ‚îÄ autobackend.py            # Auto backend selection
‚îî‚îÄ‚îÄ utils/
    ‚îú‚îÄ‚îÄ loss.py                   # Loss functions
    ‚îî‚îÄ‚îÄ metrics.py                # Evaluation metrics
```

### C√°c File C·∫ßn Ch·ªânh S·ª≠a

- **Custom Architecture**: `cfg/models/11/custom_model.yaml`
- **Custom Loss**: `ultralytics/utils/loss.py` ho·∫∑c t·∫°o file m·ªõi
- **Custom Module**: `ultralytics/nn/modules/custom_module.py`
- **Custom Trainer**: `ultralytics/models/yolo/detect/train.py` ho·∫∑c override

---

## üí° T√≥m T·∫Øt Nhanh

### ‚úÖ Nh·ªØng G√¨ C√≥ Th·ªÉ T√πy Ch·ªânh

- ‚úÖ **Backbone Architecture** - Thay ƒë·ªïi c√°c layer chi·∫øt xu·∫•t
- ‚úÖ **Neck Connections** - Thay ƒë·ªïi k·∫øt n·ªëi ƒë·∫∑c tr∆∞ng
- ‚úÖ **Head/Detection Layer** - T√πy ch·ªânh ph√°t hi·ªán
- ‚úÖ **Loss Functions** - T·∫°o custom loss
- ‚úÖ **Activation Functions** - Thay ƒë·ªïi activation
- ‚úÖ **Data Augmentation** - T√πy ch·ªânh augmentation
- ‚úÖ **Training Hyperparameters** - ƒêi·ªÅu ch·ªânh learning rate, batch size, etc.

### üìù Quy Tr√¨nh 4 B∆∞·ªõc

1. **T·∫°o YAML** - Copy v√† s·ª≠a file YAML t·ª´ templates
2. **Implement Code** - T·∫°o custom modules/losses n·∫øu c·∫ßn
3. **Train** - Ch·∫°y training v·ªõi `model.train()`
4. **Evaluate** - So s√°nh metrics v·ªõi baseline

### üéØ Cho Paper/Conference

1. ƒê·∫∑t t√™n r√µ r√†ng cho th√≠ nghi·ªám
2. Ghi l·∫°i t·∫•t c·∫£ si√™u tham s·ªë
3. So s√°nh v·ªõi baseline ƒë∆∞·ª£c c√¥ng b·ªë
4. Ghi l·∫°i parameters/FLOPs/FPS
5. V·∫Ω bi·ªÉu ƒë·ªì so s√°nh

---

## üìû Li√™n H·ªá & H·ªó Tr·ª£

- **Official Docs**: https://docs.ultralytics.com
- **GitHub**: https://github.com/ultralytics/ultralytics
- **Issues**: https://github.com/ultralytics/ultralytics/issues

---

**Generated for Ultralytics YOLO v8.3.228**

